{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A DATALOADER FOR 32 CLASSES OF GESTURE IMAGES. 24 STATIC, 8 DYNAMIC. LOAD BOTH FRAMED AND UNFRAMED, PREVENT OOM AND KERNEL CRASH. ONE-HOT ENCODING APPLIED. EXTRACT FEATURES USING A PRE-TRAINED MODEL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-21 20:31:16.706451: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-21 20:31:16.826841: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-21 20:31:16.852687: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-06-21 20:31:17.399835: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/home/nigar.alishzada/miniconda3/lib/:/home/nigar.alishzada/miniconda3/lib/python3.10/site-packages/nvidia/cudnn/lib:/home/nigar.alishzada/miniconda3/lib/:/home/nigar.alishzada/miniconda3/lib/python3.10/site-packages/nvidia/cudnn/lib:/home/nigar.alishzada/miniconda3/lib/:/home/nigar.alishzada/miniconda3/lib/python3.10/site-packages/nvidia/cudnn/lib\n",
      "2023-06-21 20:31:17.399884: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/home/nigar.alishzada/miniconda3/lib/:/home/nigar.alishzada/miniconda3/lib/python3.10/site-packages/nvidia/cudnn/lib:/home/nigar.alishzada/miniconda3/lib/:/home/nigar.alishzada/miniconda3/lib/python3.10/site-packages/nvidia/cudnn/lib:/home/nigar.alishzada/miniconda3/lib/:/home/nigar.alishzada/miniconda3/lib/python3.10/site-packages/nvidia/cudnn/lib\n",
      "2023-06-21 20:31:17.399888: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "#import dependencies\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define constants\n",
    "DATA_DIR = 'fingerspelling_framed'\n",
    "FRAMED_LETTERS = ['Ç','D','G','K','Ö','Ü','Y','Z']\n",
    "IMG_HEIGHT = 72\n",
    "IMG_WIDTH = 72\n",
    "LIST_OF_LETTERS = os.listdir(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'T': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'P': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'G': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'Ş': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], 'Y': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'Ü': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], 'Q': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'F': [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'U': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'S': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'A': [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'D': [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'H': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'E': [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'İ': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], 'L': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'Z': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'N': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'B': [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'O': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'X': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'J': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'Ö': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'I': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'R': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'Ç': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'M': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'V': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'C': [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'Ə': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], 'K': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'Ğ': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]}\n"
     ]
    }
   ],
   "source": [
    "# create an instance of the OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# encode the list elements\n",
    "one_hot_encoded = encoder.fit_transform(np.array(LIST_OF_LETTERS).reshape(-1, 1))\n",
    "\n",
    "# create a dictionary with the list elements as keys and their one hot encoding as values\n",
    "encoding_dict = {k:v for k, v in zip(LIST_OF_LETTERS, one_hot_encoded.toarray().tolist())}\n",
    "\n",
    "# print the dictionary\n",
    "print(encoding_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test encodings\n",
    "len(list(encoding_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_unframed(letter_directory):\n",
    "    # Transforming images to tensors\n",
    "    letter_list = []\n",
    "    \n",
    "    for img in os.listdir(letter_directory):\n",
    "#         print(img[-3:])\n",
    "        if img[-3:] == \"jpg\":\n",
    "            #reading each image\n",
    "            img = tf.io.read_file(os.path.join(letter_directory, img))\n",
    "            tensor = tf.io.decode_image(img, channels=3, dtype=tf.dtypes.float32)\n",
    "\n",
    "            #resizing each image and transforming to numpy array\n",
    "            tensor = tf.image.resize(tensor, [IMG_HEIGHT,IMG_WIDTH])\n",
    "            # Each image 20 times\n",
    "            letter_list += [[tensor]*20]\n",
    "        \n",
    "        \n",
    "    #CONVERT PYTHON LIST OBJECT TO THE TENSOR\n",
    "    \n",
    "    letter_list = tf.convert_to_tensor(\n",
    "                            letter_list, dtype=None, dtype_hint=None, name=None\n",
    "                            )\n",
    "    \n",
    "#     letter_list = np.array(letter_list)\n",
    "    return letter_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_framed(letter_directory):\n",
    "    # Transforming images to tensors\n",
    "    letter_list = []\n",
    "    for img in os.listdir(letter_directory):\n",
    "        #reading each image\n",
    "        img = tf.io.read_file(os.path.join(letter_directory, img))\n",
    "        tensor = tf.io.decode_image(img, channels=3, dtype=tf.dtypes.float32)\n",
    "        \n",
    "        #resizing each image and transforming to numpy array\n",
    "        tensor = tf.image.resize(tensor, [IMG_HEIGHT, IMG_WIDTH])\n",
    "        # tensor += [[tensor]*20]\n",
    "        letter_list.append(tensor)\n",
    "        \n",
    "    # Stacking tensors by 20\n",
    "    x = []\n",
    "    s = 0\n",
    "    e = 20\n",
    "    while e<=(len(letter_list)):\n",
    "        temp = []\n",
    "\n",
    "        for i in range(s, e):\n",
    "            temp.append(letter_list[i])\n",
    "        x.append(temp)\n",
    "        s+=20\n",
    "        e+=20\n",
    "    \n",
    "    # letter_list = np.array(letter_list)\n",
    "    #convert to tensor\n",
    "    letter_list = tf.convert_to_tensor(\n",
    "                            x , dtype=None, dtype_hint=None, name=None\n",
    "                            )\n",
    "    return letter_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(letter):\n",
    "    print(letter)\n",
    "    if letter in FRAMED_LETTERS:\n",
    "        X_letter = resize_framed(DATA_DIR+f\"/{letter}\")\n",
    "        letter_data_shape =  X_letter.shape\n",
    "        \n",
    "    else:   \n",
    "        X_letter = resize_unframed(DATA_DIR+f\"/{letter}\")\n",
    "        letter_data_shape =  X_letter.shape\n",
    "        \n",
    "    \n",
    "    Y_letter = [encoding_dict[letter]]*letter_data_shape[0]\n",
    "\n",
    "    Y_letter = tf.convert_to_tensor(\n",
    "                            Y_letter, dtype=None, dtype_hint=None, name=None\n",
    "                         )\n",
    "    print(X_letter.shape)\n",
    "    return X_letter,Y_letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-21 20:31:29.217331: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-21 20:31:29.999882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9624 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:17:00.0, compute capability: 7.5\n",
      "2023-06-21 20:31:30.000397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 9560 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 20, 72, 72, 3)\n",
      "P\n",
      "(40, 20, 72, 72, 3)\n",
      "G\n",
      "(40, 20, 72, 72, 3)\n",
      "Ş\n",
      "(40, 20, 72, 72, 3)\n",
      "Y\n",
      "(40, 20, 72, 72, 3)\n",
      "Ü\n",
      "(40, 20, 72, 72, 3)\n",
      "Q\n",
      "(40, 20, 72, 72, 3)\n",
      "F\n",
      "(40, 20, 72, 72, 3)\n",
      "U\n",
      "(39, 20, 72, 72, 3)\n",
      "S\n",
      "(40, 20, 72, 72, 3)\n",
      "A\n",
      "(40, 20, 72, 72, 3)\n",
      "D\n",
      "(40, 20, 72, 72, 3)\n",
      "H\n",
      "(40, 20, 72, 72, 3)\n",
      "E\n",
      "(40, 20, 72, 72, 3)\n",
      "İ\n",
      "(40, 20, 72, 72, 3)\n",
      "L\n",
      "(40, 20, 72, 72, 3)\n",
      "Z\n",
      "(40, 20, 72, 72, 3)\n",
      "N\n",
      "(40, 20, 72, 72, 3)\n",
      "B\n",
      "(40, 20, 72, 72, 3)\n",
      "O\n",
      "(40, 20, 72, 72, 3)\n",
      "X\n",
      "(40, 20, 72, 72, 3)\n",
      "J\n",
      "(40, 20, 72, 72, 3)\n",
      "Ö\n",
      "(40, 20, 72, 72, 3)\n",
      "I\n",
      "(40, 20, 72, 72, 3)\n",
      "R\n",
      "(40, 20, 72, 72, 3)\n",
      "Ç\n",
      "(40, 20, 72, 72, 3)\n",
      "M\n",
      "(40, 20, 72, 72, 3)\n",
      "V\n",
      "(40, 20, 72, 72, 3)\n",
      "C\n",
      "(40, 20, 72, 72, 3)\n",
      "Ə\n",
      "(40, 20, 72, 72, 3)\n",
      "K\n",
      "(40, 20, 72, 72, 3)\n",
      "Ğ\n",
      "(40, 20, 72, 72, 3)\n"
     ]
    }
   ],
   "source": [
    "for letter in LIST_OF_LETTERS:\n",
    "    X_letter,Y_letter = create_data(letter)\n",
    "    X.append(X_letter), Y.append(Y_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.concat(X,axis = 0)\n",
    "Y = tf.concat(Y,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1279, 20, 72, 72, 3]), TensorShape([1279, 32]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((X, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(buffer_size=X.shape[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset = dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_batch shape: (32, 20, 72, 72, 3)\n",
      "y_batch shape: (32, 32)\n",
      "X_batch shape: (32, 20, 72, 72, 3)\n",
      "y_batch shape: (32, 32)\n",
      "X_batch shape: (32, 20, 72, 72, 3)\n",
      "y_batch shape: (32, 32)\n",
      "X_batch shape: (32, 20, 72, 72, 3)\n",
      "y_batch shape: (32, 32)\n",
      "X_batch shape: (32, 20, 72, 72, 3)\n",
      "y_batch shape: (32, 32)\n",
      "X_batch shape: (32, 20, 72, 72, 3)\n",
      "y_batch shape: (32, 32)\n",
      "X_batch shape: (32, 20, 72, 72, 3)\n",
      "y_batch shape: (32, 32)\n",
      "X_batch shape: (32, 20, 72, 72, 3)\n",
      "y_batch shape: (32, 32)\n"
     ]
    }
   ],
   "source": [
    "# Testing the dataset variable\n",
    "for X_batch, y_batch in dataset.take(8):\n",
    "    print(\"X_batch shape:\", X_batch.shape)\n",
    "    print(\"y_batch shape:\", y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
